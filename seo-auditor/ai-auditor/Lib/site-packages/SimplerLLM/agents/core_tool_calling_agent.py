from pydantic import BaseModel
from SimplerLLM.language.llm import LLM
from SimplerLLM.prompts.messages_template import MessagesTemplate
from SimplerLLM.prompts.hub.agentic_prompts import tool_calling_agent_system_prompt
from SimplerLLM.utils.custom_verbose import verbose_print
from SimplerLLM.tools.json_helpers import extract_json_from_text
from SimplerLLM.tools.predefined_tools import PREDEFINED_TOOLS
import json

class ToolCallingAgentResponse(BaseModel):
    """
    A model for storing the response from the ToolAgent.
    Attributes:
        user_query (str): The original query from the user.
        agent_output (str): The output generated by the tool or directly from the language model.
    """
    user_query: str
    agent_output: str

class ToolCallingAgent:
    """
    A tool managing agent that interfaces with a language model to process and respond to user queries.

    Attributes:
        verbose (bool): If set to True, enables detailed logging for debugging purposes.
        llm_instance (LLM): An instance of a language model from the SimplerLLM library.
        available_actions (dict): A dictionary to store available tool functions mapped to their descriptions.
        system_prompt_template (str): A template used to construct the system prompt for the language model.
    """
    
    def __init__(self, llm_instance: LLM, agent_system_prompt=tool_calling_agent_system_prompt, verbose: bool=False):
        """
        Initializes the ToolAgent with necessary parameters.

        Parameters:
            llm_instance (LLM): An instance of the language model to be used.
            agent_system_prompt (str): The system prompt template for generating responses.
            verbose (bool): Flag to turn on verbose logging for debugging.
        """
        self.verbose = verbose
        self.llm_instance = llm_instance
        self.available_actions = {}
        self.system_prompt_template = agent_system_prompt
        if self.verbose:
            verbose_print("Initialized ToolAgent with verbose mode.", "info")

    def add_tool(self, tool_function):
        """
        Adds a tool to the agent's available actions.

        Parameters:
            tool_function (callable): The function representing the tool to be added.

        Raises:
            ValueError: If the tool function is not predefined or properly decorated as a custom tool.
        """
        try:
            if tool_function in PREDEFINED_TOOLS.values():
                tool_name = next(name for name, func in PREDEFINED_TOOLS.items() if func == tool_function)
                description = tool_function.__doc__.strip()
            elif hasattr(tool_function, 'is_custom_tool') and tool_function.is_custom_tool:
                tool_name = tool_function.__name__
                description = tool_function.description
            else:
                raise ValueError("Tool function must be predefined or decorated as a custom tool.")

            self.available_actions[tool_name] = {
                "function": tool_function,
                "description": description
            }
            if self.verbose:
                verbose_print(f"Added tool: {tool_name} with description: {description}", "info")
        except Exception as e:
            if self.verbose:
                verbose_print(f"Error in add_tool: {str(e)}", "error")
            raise

    def construct_system_prompt(self):
        """
        Constructs the system prompt from the available actions to guide the language model.

        Returns:
            str: The formatted system prompt incorporating descriptions of all available actions.
        """
        actions_description = "\n".join(
            [f"{name}:\n {details['description']}"
             for name, details in self.available_actions.items()]
        )
        return self.system_prompt_template.format(actions_list=actions_description)

    
    
    def generate_response(self, user_query: str = None, messages: MessagesTemplate = None, execute_tool: bool =True, ):
            """
            Generates a response to a user query using the language model and available tools.

            Parameters:
                user_query (str): The user's query to process.
                execute_tool (bool): Whether to execute the tool function if applicable.
                message_history: A history of past messages (not currently used).

            Returns:
                ToolAgentResponse: The response from the agent, either as direct LLM output or processed by a tool.
            """
            agent_system_prompt = self.construct_system_prompt()


            if user_query and messages:
                raise ValueError("Only one of 'user_query' or 'messages' should be provided.")

            #used to extract last user query in case messages were provided instead of single prompt
            user_request = ""

            if user_query:
                agent_response = self.llm_instance.generate_response(prompt=user_query, system_prompt=agent_system_prompt)
                user_request = user_query
            if messages:
                history = messages.get_messages()
                agent_response = self.llm_instance.generate_response(messages=history, system_prompt=agent_system_prompt)
                user_request = history[-1]['content']
            

        
            
            if self.verbose:
                verbose_print(f"LLM Response: {agent_response}", "info")

            # Attempt to extract a JSON action from the LLM response
            try:
                action_json = extract_json_from_text(agent_response)
            except json.JSONDecodeError:
                if self.verbose:
                    verbose_print("Failed to decode JSON from response.", "error")
                action_json = None

            # Handle response based on the presence of an actionable JSON
            if action_json:
                function_name = action_json[0].get('function_name')
                function_params = action_json[0].get('function_params', {})
                if function_name not in self.available_actions:
                    raise Exception(f"Unknown action: {function_name}")

                tool_agent_response = ToolCallingAgentResponse(
                    user_query=user_request,
                    agent_output=str(action_json[0])
                )

                if execute_tool:
                    action_function = self.available_actions[function_name]["function"]
                    tool_agent_response.agent_output = action_function(**function_params)

                    if self.verbose:
                        verbose_print(f"Executed {function_name} with parameters {function_params}.", "info")

                return tool_agent_response
            else:
                if self.verbose:
                    verbose_print("No action JSON found; returning LLM response directly.", "info")
                return ToolCallingAgentResponse(user_query=user_request, agent_output=agent_response)
